{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lucas/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_hour</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>972</th>\n",
       "      <th>973</th>\n",
       "      <th>980</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>99300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-08-18 16:00:00</td>\n",
       "      <td>103</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>1919</td>\n",
       "      <td>667</td>\n",
       "      <td>610</td>\n",
       "      <td>642</td>\n",
       "      <td>1694</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>609</td>\n",
       "      <td>208</td>\n",
       "      <td>194</td>\n",
       "      <td>207</td>\n",
       "      <td>161282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-08-18 17:00:00</td>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>1348</td>\n",
       "      <td>462</td>\n",
       "      <td>429</td>\n",
       "      <td>457</td>\n",
       "      <td>1226</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>377</td>\n",
       "      <td>136</td>\n",
       "      <td>126</td>\n",
       "      <td>115</td>\n",
       "      <td>108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-08-18 18:00:00</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>914</td>\n",
       "      <td>304</td>\n",
       "      <td>286</td>\n",
       "      <td>324</td>\n",
       "      <td>929</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>212</td>\n",
       "      <td>88</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>77076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-08-18 19:00:00</td>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>653</td>\n",
       "      <td>210</td>\n",
       "      <td>208</td>\n",
       "      <td>235</td>\n",
       "      <td>799</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>160</td>\n",
       "      <td>65</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>60118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-08-18 20:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>551</td>\n",
       "      <td>183</td>\n",
       "      <td>174</td>\n",
       "      <td>194</td>\n",
       "      <td>834</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>153</td>\n",
       "      <td>58</td>\n",
       "      <td>42</td>\n",
       "      <td>53</td>\n",
       "      <td>54592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2012-08-26 11:00:00</td>\n",
       "      <td>235</td>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>57</td>\n",
       "      <td>846</td>\n",
       "      <td>357</td>\n",
       "      <td>188</td>\n",
       "      <td>301</td>\n",
       "      <td>3308</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>90</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>939</td>\n",
       "      <td>260</td>\n",
       "      <td>315</td>\n",
       "      <td>364</td>\n",
       "      <td>244852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2012-08-26 12:00:00</td>\n",
       "      <td>219</td>\n",
       "      <td>81</td>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "      <td>928</td>\n",
       "      <td>381</td>\n",
       "      <td>207</td>\n",
       "      <td>340</td>\n",
       "      <td>3314</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>941</td>\n",
       "      <td>278</td>\n",
       "      <td>313</td>\n",
       "      <td>350</td>\n",
       "      <td>241728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2012-08-26 13:00:00</td>\n",
       "      <td>187</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>771</td>\n",
       "      <td>303</td>\n",
       "      <td>172</td>\n",
       "      <td>296</td>\n",
       "      <td>2966</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>79</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>876</td>\n",
       "      <td>262</td>\n",
       "      <td>299</td>\n",
       "      <td>315</td>\n",
       "      <td>220012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2012-08-26 14:00:00</td>\n",
       "      <td>175</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>592</td>\n",
       "      <td>200</td>\n",
       "      <td>139</td>\n",
       "      <td>253</td>\n",
       "      <td>2572</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>794</td>\n",
       "      <td>276</td>\n",
       "      <td>233</td>\n",
       "      <td>285</td>\n",
       "      <td>198886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2012-08-26 15:00:00</td>\n",
       "      <td>159</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>366</td>\n",
       "      <td>128</td>\n",
       "      <td>70</td>\n",
       "      <td>168</td>\n",
       "      <td>2056</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>709</td>\n",
       "      <td>247</td>\n",
       "      <td>223</td>\n",
       "      <td>239</td>\n",
       "      <td>159072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows Ã— 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time_hour    0   1   2   3    10   11   12   13    20  ...  972  \\\n",
       "0   2012-08-18 16:00:00  103  32  35  36  1919  667  610  642  1694  ...   20   \n",
       "1   2012-08-18 17:00:00   78  31  20  27  1348  462  429  457  1226  ...   15   \n",
       "2   2012-08-18 18:00:00   36  17   9  10   914  304  286  324   929  ...   10   \n",
       "3   2012-08-18 19:00:00   32  14   7  11   653  210  208  235   799  ...    8   \n",
       "4   2012-08-18 20:00:00   23   7   5  11   551  183  174  194   834  ...   15   \n",
       "..                  ...  ...  ..  ..  ..   ...  ...  ...  ...   ...  ...  ...   \n",
       "187 2012-08-26 11:00:00  235  84  94  57   846  357  188  301  3308  ...   55   \n",
       "188 2012-08-26 12:00:00  219  81  77  61   928  381  207  340  3314  ...   64   \n",
       "189 2012-08-26 13:00:00  187  67  63  57   771  303  172  296  2966  ...   50   \n",
       "190 2012-08-26 14:00:00  175  57  62  56   592  200  139  253  2572  ...   41   \n",
       "191 2012-08-26 15:00:00  159  53  56  50   366  128   70  168  2056  ...   32   \n",
       "\n",
       "     973  980  982  983  990  991  992  993   99300  \n",
       "0     47   32   11   21  609  208  194  207  161282  \n",
       "1     37   16    7    9  377  136  126  115  108600  \n",
       "2     28   14    5    9  212   88   70   54   77076  \n",
       "3     22   11    4    7  160   65   44   51   60118  \n",
       "4     21    8    2    6  153   58   42   53   54592  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...     ...  \n",
       "187   90   38   11   27  939  260  315  364  244852  \n",
       "188   88   41   16   25  941  278  313  350  241728  \n",
       "189   79   36   17   19  876  262  299  315  220012  \n",
       "190   90   33   14   19  794  276  233  285  198886  \n",
       "191   58   39   14   25  709  247  223  239  159072  \n",
       "\n",
       "[192 rows x 401 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = \"../data/users.h5\"\n",
    "users_df = pd.read_hdf(dataset_file)\n",
    "users_df = pd.DataFrame(users_df.to_records())\n",
    "users_df = users_df\n",
    "users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "window = 12\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "num_input = len(users_df.columns[1:])\n",
    "timesteps = users_df.shape[0]\n",
    "keep_rate_DROPOUT = 1;\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "loss_function = \"mean_squared_error\"\n",
    "lstm_units = 50\n",
    "bs = \"10\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:                    0.01\n",
      "epochs:                           500\n",
      "Keep Rate DROPOUT:                1\n",
      "Number of input(Metrics):         400\n",
      "Time steps:                       192\n",
      "Batch size:                       32\n"
     ]
    }
   ],
   "source": [
    "print(\"Learning rate:                   \", learning_rate)\n",
    "print(\"epochs:                          \", epochs)\n",
    "print(\"Keep Rate DROPOUT:               \", keep_rate_DROPOUT)\n",
    "\n",
    "print(\"Number of input(Metrics):        \", num_input)\n",
    "print(\"Time steps:                      \", timesteps)\n",
    "print(\"Batch size:                      \", batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   103,     32,     35, ...,    194,    207, 161282],\n",
       "       [    78,     31,     20, ...,    126,    115, 108600],\n",
       "       [    36,     17,      9, ...,     70,     54,  77076],\n",
       "       ...,\n",
       "       [   187,     67,     63, ...,    299,    315, 220012],\n",
       "       [   175,     57,     62, ...,    233,    285, 198886],\n",
       "       [   159,     53,     56, ...,    223,    239, 159072]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = users_df[users_df.columns[1:]].to_numpy()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_len = math.ceil(len(dataset) * .8)\n",
    "train_data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30258303, 0.23684211, 0.33707865, ..., 0.43603133, 0.30418251,\n",
       "        0.28341841],\n",
       "       [0.2103321 , 0.22807018, 0.16853933, ..., 0.25848564, 0.12927757,\n",
       "        0.1546292 ],\n",
       "       [0.05535055, 0.10526316, 0.04494382, ..., 0.11227154, 0.01330798,\n",
       "        0.07756395],\n",
       "       ...,\n",
       "       [0.61254613, 0.54385965, 0.65168539, ..., 0.71018277, 0.5095057 ,\n",
       "        0.42699288],\n",
       "       [0.56826568, 0.45614035, 0.64044944, ..., 0.53785901, 0.45247148,\n",
       "        0.37534714],\n",
       "       [0.50922509, 0.42105263, 0.57303371, ..., 0.51174935, 0.36501901,\n",
       "        0.27801572]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = scaled_data[0:train_data_len, :]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 400)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = scaled_data[train_data_len - window:, :]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = []\n",
    "YTrain = []\n",
    "\n",
    "for i in range(window, len(train_data)):\n",
    "    XTrain.append(train_data[i-window:i])\n",
    "    YTrain.append(train_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 12, 400)\n",
      "(142, 400)\n"
     ]
    }
   ],
   "source": [
    "XTrain, YTrain = np.array(XTrain), np.array(YTrain)\n",
    "print(XTrain.shape)\n",
    "print(YTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Sequential()\n",
    "m.add(LSTM(units=lstm_units, return_sequences=True, input_shape=(XTrain.shape[1], num_input)))\n",
    "m.add(Dropout(keep_rate_DROPOUT))\n",
    "m.add(LSTM(units=lstm_units))\n",
    "m.add(Dropout(keep_rate_DROPOUT))\n",
    "m.add(Dense(units=num_input))\n",
    "m.compile(optimizer=optimizer, loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lucas/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/500\n",
      "142/142 [==============================] - 0s 3ms/step - loss: 0.1821\n",
      "Epoch 2/500\n",
      "142/142 [==============================] - 0s 339us/step - loss: 0.0757\n",
      "Epoch 3/500\n",
      "142/142 [==============================] - 0s 331us/step - loss: 0.0571\n",
      "Epoch 4/500\n",
      "142/142 [==============================] - 0s 344us/step - loss: 0.0366\n",
      "Epoch 5/500\n",
      "142/142 [==============================] - 0s 317us/step - loss: 0.0253\n",
      "Epoch 6/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0205\n",
      "Epoch 7/500\n",
      "142/142 [==============================] - 0s 322us/step - loss: 0.0173\n",
      "Epoch 8/500\n",
      "142/142 [==============================] - 0s 380us/step - loss: 0.0158\n",
      "Epoch 9/500\n",
      "142/142 [==============================] - 0s 437us/step - loss: 0.0156\n",
      "Epoch 10/500\n",
      "142/142 [==============================] - 0s 335us/step - loss: 0.0145\n",
      "Epoch 11/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0142\n",
      "Epoch 12/500\n",
      "142/142 [==============================] - 0s 285us/step - loss: 0.0142\n",
      "Epoch 13/500\n",
      "142/142 [==============================] - 0s 310us/step - loss: 0.0134\n",
      "Epoch 14/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0130\n",
      "Epoch 15/500\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.0131\n",
      "Epoch 16/500\n",
      "142/142 [==============================] - 0s 302us/step - loss: 0.0126\n",
      "Epoch 17/500\n",
      "142/142 [==============================] - 0s 287us/step - loss: 0.0127\n",
      "Epoch 18/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0125\n",
      "Epoch 19/500\n",
      "142/142 [==============================] - 0s 286us/step - loss: 0.0120\n",
      "Epoch 20/500\n",
      "142/142 [==============================] - 0s 304us/step - loss: 0.0115\n",
      "Epoch 21/500\n",
      "142/142 [==============================] - 0s 289us/step - loss: 0.0112\n",
      "Epoch 22/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0105\n",
      "Epoch 23/500\n",
      "142/142 [==============================] - 0s 294us/step - loss: 0.0098\n",
      "Epoch 24/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0093\n",
      "Epoch 25/500\n",
      "142/142 [==============================] - 0s 301us/step - loss: 0.0091\n",
      "Epoch 26/500\n",
      "142/142 [==============================] - 0s 309us/step - loss: 0.0086\n",
      "Epoch 27/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0083\n",
      "Epoch 28/500\n",
      "142/142 [==============================] - 0s 298us/step - loss: 0.0081\n",
      "Epoch 29/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0081\n",
      "Epoch 30/500\n",
      "142/142 [==============================] - 0s 305us/step - loss: 0.0080\n",
      "Epoch 31/500\n",
      "142/142 [==============================] - 0s 296us/step - loss: 0.0079\n",
      "Epoch 32/500\n",
      "142/142 [==============================] - 0s 298us/step - loss: 0.0081\n",
      "Epoch 33/500\n",
      "142/142 [==============================] - 0s 287us/step - loss: 0.0079\n",
      "Epoch 34/500\n",
      "142/142 [==============================] - 0s 298us/step - loss: 0.0078\n",
      "Epoch 35/500\n",
      "142/142 [==============================] - 0s 289us/step - loss: 0.0080\n",
      "Epoch 36/500\n",
      "142/142 [==============================] - 0s 293us/step - loss: 0.0082\n",
      "Epoch 37/500\n",
      "142/142 [==============================] - 0s 298us/step - loss: 0.0079\n",
      "Epoch 38/500\n",
      "142/142 [==============================] - 0s 299us/step - loss: 0.0077\n",
      "Epoch 39/500\n",
      "142/142 [==============================] - 0s 310us/step - loss: 0.0075\n",
      "Epoch 40/500\n",
      "142/142 [==============================] - 0s 293us/step - loss: 0.0074\n",
      "Epoch 41/500\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.0074\n",
      "Epoch 42/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0074\n",
      "Epoch 43/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0074\n",
      "Epoch 44/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0073\n",
      "Epoch 45/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0074\n",
      "Epoch 46/500\n",
      "142/142 [==============================] - 0s 303us/step - loss: 0.0075\n",
      "Epoch 47/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0074\n",
      "Epoch 48/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0073\n",
      "Epoch 49/500\n",
      "142/142 [==============================] - 0s 289us/step - loss: 0.0072\n",
      "Epoch 50/500\n",
      "142/142 [==============================] - 0s 315us/step - loss: 0.0071\n",
      "Epoch 51/500\n",
      "142/142 [==============================] - 0s 304us/step - loss: 0.0072\n",
      "Epoch 52/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0071\n",
      "Epoch 53/500\n",
      "142/142 [==============================] - 0s 303us/step - loss: 0.0068\n",
      "Epoch 54/500\n",
      "142/142 [==============================] - 0s 306us/step - loss: 0.0068\n",
      "Epoch 55/500\n",
      "142/142 [==============================] - 0s 317us/step - loss: 0.0066\n",
      "Epoch 56/500\n",
      "142/142 [==============================] - 0s 298us/step - loss: 0.0065\n",
      "Epoch 57/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0064\n",
      "Epoch 58/500\n",
      "142/142 [==============================] - 0s 296us/step - loss: 0.0063\n",
      "Epoch 59/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0062\n",
      "Epoch 60/500\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.0062\n",
      "Epoch 61/500\n",
      "142/142 [==============================] - 0s 304us/step - loss: 0.0061\n",
      "Epoch 62/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0060\n",
      "Epoch 63/500\n",
      "142/142 [==============================] - 0s 310us/step - loss: 0.0059\n",
      "Epoch 64/500\n",
      "142/142 [==============================] - 0s 326us/step - loss: 0.0058\n",
      "Epoch 65/500\n",
      "142/142 [==============================] - 0s 341us/step - loss: 0.0057\n",
      "Epoch 66/500\n",
      "142/142 [==============================] - 0s 316us/step - loss: 0.0056\n",
      "Epoch 67/500\n",
      "142/142 [==============================] - 0s 302us/step - loss: 0.0055\n",
      "Epoch 68/500\n",
      "142/142 [==============================] - 0s 305us/step - loss: 0.0054\n",
      "Epoch 69/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0054\n",
      "Epoch 70/500\n",
      "142/142 [==============================] - 0s 301us/step - loss: 0.0054\n",
      "Epoch 71/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0053\n",
      "Epoch 72/500\n",
      "142/142 [==============================] - 0s 320us/step - loss: 0.0053\n",
      "Epoch 73/500\n",
      "142/142 [==============================] - 0s 312us/step - loss: 0.0053\n",
      "Epoch 74/500\n",
      "142/142 [==============================] - 0s 294us/step - loss: 0.0053\n",
      "Epoch 75/500\n",
      "142/142 [==============================] - 0s 301us/step - loss: 0.0052\n",
      "Epoch 76/500\n",
      "142/142 [==============================] - 0s 305us/step - loss: 0.0049\n",
      "Epoch 77/500\n",
      "142/142 [==============================] - 0s 306us/step - loss: 0.0049\n",
      "Epoch 78/500\n",
      "142/142 [==============================] - 0s 302us/step - loss: 0.0049\n",
      "Epoch 79/500\n",
      "142/142 [==============================] - 0s 308us/step - loss: 0.0048\n",
      "Epoch 80/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0048\n",
      "Epoch 81/500\n",
      "142/142 [==============================] - 0s 381us/step - loss: 0.0051\n",
      "Epoch 82/500\n",
      "142/142 [==============================] - 0s 645us/step - loss: 0.0049\n",
      "Epoch 83/500\n",
      "142/142 [==============================] - 0s 547us/step - loss: 0.0050\n",
      "Epoch 84/500\n",
      "142/142 [==============================] - 0s 352us/step - loss: 0.0048\n",
      "Epoch 85/500\n",
      "142/142 [==============================] - 0s 321us/step - loss: 0.0047\n",
      "Epoch 86/500\n",
      "142/142 [==============================] - 0s 338us/step - loss: 0.0046\n",
      "Epoch 87/500\n",
      "142/142 [==============================] - 0s 311us/step - loss: 0.0047\n",
      "Epoch 88/500\n",
      "142/142 [==============================] - 0s 302us/step - loss: 0.0045\n",
      "Epoch 89/500\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.0044\n",
      "Epoch 90/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0044\n",
      "Epoch 91/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0044\n",
      "Epoch 92/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0043\n",
      "Epoch 93/500\n",
      "142/142 [==============================] - 0s 307us/step - loss: 0.0043\n",
      "Epoch 94/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0042\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 302us/step - loss: 0.0043\n",
      "Epoch 96/500\n",
      "142/142 [==============================] - 0s 284us/step - loss: 0.0041\n",
      "Epoch 97/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0041\n",
      "Epoch 98/500\n",
      "142/142 [==============================] - 0s 286us/step - loss: 0.0041\n",
      "Epoch 99/500\n",
      "142/142 [==============================] - 0s 284us/step - loss: 0.0041\n",
      "Epoch 100/500\n",
      "142/142 [==============================] - 0s 279us/step - loss: 0.0042\n",
      "Epoch 101/500\n",
      "142/142 [==============================] - 0s 278us/step - loss: 0.0041\n",
      "Epoch 102/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0040\n",
      "Epoch 103/500\n",
      "142/142 [==============================] - 0s 280us/step - loss: 0.0040\n",
      "Epoch 104/500\n",
      "142/142 [==============================] - 0s 284us/step - loss: 0.0039\n",
      "Epoch 105/500\n",
      "142/142 [==============================] - 0s 281us/step - loss: 0.0039\n",
      "Epoch 106/500\n",
      "142/142 [==============================] - 0s 279us/step - loss: 0.0039\n",
      "Epoch 107/500\n",
      "142/142 [==============================] - 0s 279us/step - loss: 0.0039\n",
      "Epoch 108/500\n",
      "142/142 [==============================] - 0s 280us/step - loss: 0.0039\n",
      "Epoch 109/500\n",
      "142/142 [==============================] - 0s 284us/step - loss: 0.0039\n",
      "Epoch 110/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0039\n",
      "Epoch 111/500\n",
      "142/142 [==============================] - 0s 286us/step - loss: 0.0038\n",
      "Epoch 112/500\n",
      "142/142 [==============================] - 0s 279us/step - loss: 0.0037\n",
      "Epoch 113/500\n",
      "142/142 [==============================] - 0s 284us/step - loss: 0.0039\n",
      "Epoch 114/500\n",
      "142/142 [==============================] - 0s 285us/step - loss: 0.0039\n",
      "Epoch 115/500\n",
      "142/142 [==============================] - 0s 281us/step - loss: 0.0039\n",
      "Epoch 116/500\n",
      "142/142 [==============================] - 0s 276us/step - loss: 0.0038\n",
      "Epoch 117/500\n",
      "142/142 [==============================] - 0s 299us/step - loss: 0.0038\n",
      "Epoch 118/500\n",
      "142/142 [==============================] - 0s 278us/step - loss: 0.0037\n",
      "Epoch 119/500\n",
      "142/142 [==============================] - 0s 302us/step - loss: 0.0037\n",
      "Epoch 120/500\n",
      "142/142 [==============================] - 0s 274us/step - loss: 0.0037\n",
      "Epoch 121/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0037\n",
      "Epoch 122/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0036\n",
      "Epoch 123/500\n",
      "142/142 [==============================] - 0s 283us/step - loss: 0.0036\n",
      "Epoch 124/500\n",
      "142/142 [==============================] - 0s 285us/step - loss: 0.0036\n",
      "Epoch 125/500\n",
      "142/142 [==============================] - 0s 287us/step - loss: 0.0035\n",
      "Epoch 126/500\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.0034\n",
      "Epoch 127/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0035\n",
      "Epoch 128/500\n",
      "142/142 [==============================] - 0s 301us/step - loss: 0.0035\n",
      "Epoch 129/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0035\n",
      "Epoch 130/500\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.0035\n",
      "Epoch 131/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0034\n",
      "Epoch 132/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0034\n",
      "Epoch 133/500\n",
      "142/142 [==============================] - 0s 294us/step - loss: 0.0034\n",
      "Epoch 134/500\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.0034\n",
      "Epoch 135/500\n",
      "142/142 [==============================] - 0s 287us/step - loss: 0.0034\n",
      "Epoch 136/500\n",
      "142/142 [==============================] - 0s 282us/step - loss: 0.0033\n",
      "Epoch 137/500\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.0033\n",
      "Epoch 138/500\n",
      "142/142 [==============================] - 0s 287us/step - loss: 0.0033\n",
      "Epoch 139/500\n",
      "142/142 [==============================] - 0s 287us/step - loss: 0.0034\n",
      "Epoch 140/500\n",
      "142/142 [==============================] - 0s 282us/step - loss: 0.0033\n",
      "Epoch 141/500\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.0033\n",
      "Epoch 142/500\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.0033\n",
      "Epoch 143/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0034\n",
      "Epoch 144/500\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.0034\n",
      "Epoch 145/500\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.0033\n",
      "Epoch 146/500\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.0035\n",
      "Epoch 147/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0036\n",
      "Epoch 148/500\n",
      "142/142 [==============================] - 0s 293us/step - loss: 0.0036\n",
      "Epoch 149/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0034\n",
      "Epoch 150/500\n",
      "142/142 [==============================] - 0s 284us/step - loss: 0.0034\n",
      "Epoch 151/500\n",
      "142/142 [==============================] - 0s 296us/step - loss: 0.0034\n",
      "Epoch 152/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0034\n",
      "Epoch 153/500\n",
      "142/142 [==============================] - 0s 293us/step - loss: 0.0034\n",
      "Epoch 154/500\n",
      "142/142 [==============================] - 0s 281us/step - loss: 0.0033\n",
      "Epoch 155/500\n",
      "142/142 [==============================] - 0s 289us/step - loss: 0.0033\n",
      "Epoch 156/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0033\n",
      "Epoch 157/500\n",
      "142/142 [==============================] - 0s 294us/step - loss: 0.0033\n",
      "Epoch 158/500\n",
      "142/142 [==============================] - 0s 287us/step - loss: 0.0032\n",
      "Epoch 159/500\n",
      "142/142 [==============================] - 0s 296us/step - loss: 0.0032\n",
      "Epoch 160/500\n",
      "142/142 [==============================] - 0s 284us/step - loss: 0.0031\n",
      "Epoch 161/500\n",
      "142/142 [==============================] - 0s 293us/step - loss: 0.0032\n",
      "Epoch 162/500\n",
      "142/142 [==============================] - 0s 285us/step - loss: 0.0032\n",
      "Epoch 163/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0032\n",
      "Epoch 164/500\n",
      "142/142 [==============================] - 0s 284us/step - loss: 0.0031\n",
      "Epoch 165/500\n",
      "142/142 [==============================] - 0s 306us/step - loss: 0.0031\n",
      "Epoch 166/500\n",
      "142/142 [==============================] - 0s 279us/step - loss: 0.0031\n",
      "Epoch 167/500\n",
      "142/142 [==============================] - 0s 302us/step - loss: 0.0030\n",
      "Epoch 168/500\n",
      "142/142 [==============================] - 0s 286us/step - loss: 0.0030\n",
      "Epoch 169/500\n",
      "142/142 [==============================] - 0s 293us/step - loss: 0.0031\n",
      "Epoch 170/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0030\n",
      "Epoch 171/500\n",
      "142/142 [==============================] - 0s 310us/step - loss: 0.0030\n",
      "Epoch 172/500\n",
      "142/142 [==============================] - 0s 297us/step - loss: 0.0030\n",
      "Epoch 173/500\n",
      "142/142 [==============================] - 0s 302us/step - loss: 0.0030\n",
      "Epoch 174/500\n",
      "142/142 [==============================] - 0s 293us/step - loss: 0.0030\n",
      "Epoch 175/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0030\n",
      "Epoch 176/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0030\n",
      "Epoch 177/500\n",
      "142/142 [==============================] - 0s 296us/step - loss: 0.0030\n",
      "Epoch 178/500\n",
      "142/142 [==============================] - 0s 304us/step - loss: 0.0030\n",
      "Epoch 179/500\n",
      "142/142 [==============================] - 0s 295us/step - loss: 0.0030\n",
      "Epoch 180/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0030\n",
      "Epoch 181/500\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.0029\n",
      "Epoch 182/500\n",
      "142/142 [==============================] - 0s 289us/step - loss: 0.0029\n",
      "Epoch 183/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0029\n",
      "Epoch 184/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0029\n",
      "Epoch 185/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0029\n",
      "Epoch 186/500\n",
      "142/142 [==============================] - 0s 285us/step - loss: 0.0029\n",
      "Epoch 187/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0028\n",
      "Epoch 188/500\n",
      "142/142 [==============================] - 0s 291us/step - loss: 0.0028\n",
      "Epoch 189/500\n",
      "142/142 [==============================] - 0s 315us/step - loss: 0.0028\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142/142 [==============================] - 0s 283us/step - loss: 0.0028\n",
      "Epoch 191/500\n",
      "142/142 [==============================] - 0s 294us/step - loss: 0.0028\n",
      "Epoch 192/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0028\n",
      "Epoch 193/500\n",
      "142/142 [==============================] - 0s 292us/step - loss: 0.0028\n",
      "Epoch 194/500\n",
      "142/142 [==============================] - 0s 281us/step - loss: 0.0028\n",
      "Epoch 195/500\n",
      "142/142 [==============================] - 0s 288us/step - loss: 0.0028\n",
      "Epoch 196/500\n",
      "142/142 [==============================] - 0s 283us/step - loss: 0.0028\n",
      "Epoch 197/500\n",
      "142/142 [==============================] - 0s 290us/step - loss: 0.0028\n",
      "Epoch 198/500\n",
      "142/142 [==============================] - 0s 289us/step - loss: 0.0028\n",
      "Epoch 199/500\n",
      "142/142 [==============================] - 0s 286us/step - loss: 0.0028\n",
      "Epoch 200/500\n",
      "142/142 [==============================] - 0s 286us/step - loss: 0.0028\n",
      "Epoch 201/500\n",
      "142/142 [==============================] - 0s 283us/step - loss: 0.0028\n",
      "Epoch 202/500\n",
      "142/142 [==============================] - 0s 300us/step - loss: 0.0028\n",
      "Epoch 203/500\n",
      "142/142 [==============================] - 0s 287us/step - loss: 0.0028\n",
      "Epoch 204/500\n",
      "142/142 [==============================] - 0s 294us/step - loss: 0.0028\n",
      "Epoch 205/500\n",
      "142/142 [==============================] - 0s 286us/step - loss: 0.0030\n",
      "Epoch 206/500\n",
      " 32/142 [=====>........................] - ETA: 0s - loss: 0.0029"
     ]
    }
   ],
   "source": [
    "history = m.fit(XTrain, YTrain, epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel('loss');plt.xlabel=('epoch')\n",
    "plt.semilogy(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = []\n",
    "\n",
    "YTest = dataset[train_data_len:]\n",
    "test_data\n",
    "for i in range(window, len(test_data)):\n",
    "    XTest.append(test_data[i-window:i])\n",
    "\n",
    "XTest, YTest = np.array(XTest), np.array(YTest)\n",
    "\n",
    "x_pred = m.predict(XTest)\n",
    "x_pred = scaler.inverse_transform(x_pred)\n",
    "prediction = pd.DataFrame(data=x_pred, columns=users_df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = users_df[:train_data_len]\n",
    "valid = users_df[train_data_len:]\n",
    "\n",
    "prediction['time_hour'] = valid['time_hour'].values\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "users_df.plot(x='time_hour', y=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plt.title('Model')\n",
    "ax = plt.gca()\n",
    "train.plot(x='time_hour', y=bs, ax=ax)\n",
    "valid.plot(x='time_hour', y=bs, ax=ax)\n",
    "prediction.plot(x='time_hour', y=bs, ax=ax)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "plt.title('Model')\n",
    "ax = plt.gca()\n",
    "valid.plot(x='time_hour', y=bs, ax=ax)\n",
    "prediction.plot(x='time_hour', y=bs, ax=ax)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean(x_pred - YTest)**2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean(prediction[bs].values - valid[bs].values)**2)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
